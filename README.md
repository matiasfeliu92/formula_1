# ğŸï¸ Formula 1 Data Pipeline: ETL & DBT Analysis

Este repositorio contiene un proyecto de IngenierÃ­a de Datos end-to-end centrado en el anÃ¡lisis de telemetrÃ­a y sesiones de FÃ³rmula 1. Implementa un pipeline de extracciÃ³n incremental, almacenamiento en base de datos relacional y transformaciÃ³n moderna utilizando **DBT**.

El sistema estÃ¡ diseÃ±ado para interactuar con la **OpenF1 API**, optimizando la ingesta de datos y preparando vistas analÃ­ticas para su posterior consumo.

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
2. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
3. [Arquitectura y Flujo de Datos](#arquitectura-y-flujo-de-datos)
    - [1. ExtracciÃ³n de Datos (Incremental)](#1-extracciÃ³n-de-datos-incremental)
    - [2. Carga de Datos (Raw)](#2-carga-de-datos-raw)
    - [3. TransformaciÃ³n (DBT)](#3-transformaciÃ³n-dbt)
4. [Estructura del Proyecto](#estructura-del-proyecto)
5. [InstalaciÃ³n y EjecuciÃ³n](#instalaciÃ³n-y-ejecuciÃ³n)

---

## ğŸ“– DescripciÃ³n del Proyecto

El proyecto automatiza el ciclo de vida de los datos de la FÃ³rmula 1, desde su origen en APIs pÃºblicas hasta su modelado para anÃ¡lisis. El foco principal es la eficiencia en la carga de datos (evitando descargas redundantes) y la estructuraciÃ³n modular de las transformaciones mediante DBT.

Los datos abarcan desde la temporada 2023 en adelante e incluyen detalles granulares como tiempos de vuelta, informaciÃ³n de pilotos y telemetrÃ­a del coche en tiempo real.

---

## ğŸ›  Stack TecnolÃ³gico

* **Lenguaje Principal:** Python 3.x
* **LibrerÃ­as Python:**
    * `requests`: Manejo de peticiones HTTP a la API.
    * `pandas`: ManipulaciÃ³n de datos en memoria.
    * `sqlalchemy` & `psycopg2`: ConexiÃ³n y ORM para base de datos.
* **Base de Datos:** PostgreSQL.
* **TransformaciÃ³n:** DBT (Data Build Tool).
* **Plataforma:** Databricks / Entorno Local.
* **Fuente de Datos:** [OpenF1 API](https://openf1.org/).

---

## ğŸ— Arquitectura y Flujo de Datos

El pipeline sigue una estrategia **ELT (Extract, Load, Transform)** dividida en tres etapas crÃ­ticas:

### 1. ExtracciÃ³n de Datos (Incremental)
Se obtienen datos de los siguientes endpoints de la API:
* `GET /sessions`
* `GET /meetings`
* `GET /drivers`
* `GET /laps`
* `GET /car_data`

**LÃ³gica Incremental:**
Para optimizar tiempos y recursos, el proceso no descarga el histÃ³rico completo en cada ejecuciÃ³n.
1.  El script consulta la base de datos para encontrar el Ãºltimo `session_key` y `meeting_key` registrado.
2.  Parametriza las llamadas a la API para solicitar Ãºnicamente los registros con identificadores **mayores** a los almacenados.
3.  Resultados: Solo se procesan los datos nuevos generados desde la Ãºltima ejecuciÃ³n.

### 2. Carga de Datos (Raw)
Los datos extraÃ­dos se almacenan en **PostgreSQL** en su formato original ("Raw Data").
* Cada endpoint de la API tiene su propia tabla correspondiente.
* No se aplican limpiezas en esta etapa para garantizar la integridad del dato crudo y permitir reprocesamientos futuros si la lÃ³gica de negocio cambia.

### 3. TransformaciÃ³n (DBT)
Utilizando **DBT**, los datos crudos se transforman en informaciÃ³n valiosa a travÃ©s de un linaje de datos claro:

#### Etapa A: UnificaciÃ³n (Staging/Views)
CreaciÃ³n de vistas unificadas mediante `JOINs` para desnormalizar la data. En esta etapa **no se limpia la data**, solo se consolida.

* **Vista `stg_laps_unified`:**
    * Une: `sessions` + `meetings` + `drivers` + `laps`.
    * Permite analizar tiempos de vuelta con contexto del piloto y la pista.
* **Vista `stg_telemetry_unified`:**
    * Une: `sessions` + `meetings` + `drivers` + `car_data`.
    * Consolida la telemetrÃ­a tÃ©cnica con los datos de la sesiÃ³n.

#### Etapa B: Limpieza y Enriquecimiento (Intermediate)
Se aplican reglas de negocio sobre las vistas de staging.
* **Relleno de Datos (Imputation):** Se toma la vista unificada de `Laps` y se procesan los valores nulos o faltantes para asegurar la calidad del dato antes de su uso en reportes o dashboards.

---

## ğŸ“‚ Estructura del Proyecto

```bash
formula_1/
â”œâ”€â”€ dbt_project/              # Directorio principal de DBT
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/          # Modelos de vistas unificadas (Joins)
â”‚   â”‚   â””â”€â”€ intermediate/     # Modelos de limpieza y transformaciÃ³n
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ src/                      # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ extraction.py         # Script de carga incremental
â”‚   â”œâ”€â”€ db_connection.py      # ConfiguraciÃ³n de SQLAlchemy/Postgres
â”‚   â””â”€â”€ load.py               # Ingesta a SQL
â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â””â”€â”€ README.md                 # DocumentaciÃ³n
